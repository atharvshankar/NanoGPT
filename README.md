This repo contains my code for lab1 of CSE519 the graduate level course Data Science Fundamentals offered at Stony Brook University.
I train 3 separate NanoGPTs on 3 different datasets namely shakespeare, wikipedia and math using char level tokenization. 
Further, investigate the token probabilites during generation and compare performance after finetuning.
Also build a lightweight version of GradCAM for language models to measure which tokens affect a model's probability of generating a target token.
